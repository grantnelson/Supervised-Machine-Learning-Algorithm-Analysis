{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6f2f31b88d2f0510b3ebc3fcbc24a0fb",
     "grade": false,
     "grade_id": "cell-3d278d7f3d5a4ba3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Assignment 2\n",
    "\n",
    "#### Feel free to add cells to define your helper functions.\n",
    "#### Please remove \"raise NotImplementedError()\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student 1 Name: Tamara Zubatiy A11904774\n",
    "\n",
    "Student 2 Name: Grant Nelson\n",
    "\n",
    "Tamara Zubatiy and Grant Nelson attest that this assignment was done by them two and reflects their original work and based on their understanding of the concepts. Both students have equally contributed to the solution of this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn \n",
    "import time\n",
    "import random\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import os\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "e9464b2543035fd4ff5204cffab0a6e5",
     "grade": false,
     "grade_id": "cell-382d24a442ac36ea",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def sentimentClassKNN(trainFile, testFile, k, distanceMeasure):\n",
    "    # Open and read the trainFile and testFile\n",
    "    var= open(trainFile, 'r')\n",
    "    tvar= open(testFile, 'r')\n",
    "\n",
    "    \n",
    "    #random shuffle trainFile before splitting labels\n",
    "    train = []\n",
    "    test = []\n",
    "\n",
    "    train= var.readlines()\n",
    "    test= tvar.readlines()\n",
    "    \n",
    "    var.close()\n",
    "    tvar.close()\n",
    "        \n",
    "    random.shuffle(train)  \n",
    "    random.shuffle(test)\n",
    "    \n",
    "    trainLabels=[]\n",
    "    trainData=[]\n",
    "    testLabels=[]\n",
    "    testData=[]\n",
    "        \n",
    "    # Split label and vector\n",
    "    for elements in train:\n",
    "        trainLabels.append(float(elements.split()[0]))\n",
    "        trainData.append([float(i) for i in elements.split()[1:]])\n",
    "        \n",
    "    for elements in test:\n",
    "        testLabels.append(float(elements.split()[0]))\n",
    "        testData.append([float(i) for i in elements.split()[1:]])\n",
    "        \n",
    "    # Create a KNN model\n",
    "   \n",
    "    #k-N-N\n",
    "    model=KNeighborsClassifier(n_neighbors = k, metric= distanceMeasure) #accuracy 81.85% with your k value\n",
    "    \n",
    "    \n",
    "\n",
    "    # Fit the training set into the model\n",
    "    model.fit(trainData, trainLabels)\n",
    "    \n",
    "    # Calculate and return the prediction accuracy\n",
    "    accuracy = model.score(testData, testLabels)\n",
    "    print(accuracy)\n",
    "    return accuracy\n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ece86fb6d844ff603cb0994919f7e8e7",
     "grade": true,
     "grade_id": "cell-5efea8601cd9b01e",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8185\n"
     ]
    }
   ],
   "source": [
    "knn_accu = sentimentClassKNN('train_data.txt', 'test_data.txt', 100, \"euclidean\")\n",
    "assert (0.8<knn_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "eab5841eeaf18d44edafdc121d96c33f",
     "grade": false,
     "grade_id": "cell-cdb0a02d14ecdb4f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def sentimentClassPerceptron(trainFile, testFile, n):\n",
    "    # Open and read the trainFile and testFile\n",
    "    var= open(trainFile, 'r')\n",
    "    tvar= open(testFile, 'r')\n",
    "\n",
    "    \n",
    "    #random shuffle trainFile before splitting labels\n",
    "    train = []\n",
    "    test = []\n",
    "\n",
    "    train= var.readlines()\n",
    "    test= tvar.readlines()\n",
    "    \n",
    "    var.close()\n",
    "    tvar.close()\n",
    "        \n",
    "    random.shuffle(train)  \n",
    "    random.shuffle(test)\n",
    "    \n",
    "    trainLabels=[]\n",
    "    trainData=[]\n",
    "    testLabels=[]\n",
    "    testData=[]\n",
    "        \n",
    "    # Split label and vector\n",
    "    for elements in train:\n",
    "        trainLabels.append(float(elements.split()[0]))\n",
    "        trainData.append([float(i) for i in elements.split()[1:]])\n",
    "        \n",
    "    for elements in test:\n",
    "        testLabels.append(float(elements.split()[0]))\n",
    "        testData.append([float(i) for i in elements.split()[1:]])\n",
    "     #make the model\n",
    "   \n",
    "    model=sklearn.linear_model.Perceptron(n_iter=n)\n",
    "     # Fit the training set into the model\n",
    "    model.fit(trainData, trainLabels)\n",
    "    \n",
    "    # Calculate and return the prediction accuracy\n",
    "    accuracy = model.score(testData, testLabels)\n",
    "    print(accuracy)\n",
    "    return accuracy\n",
    "    \n",
    "    \n",
    "    \n",
    "    raise NotImplementedError()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ad5e8483ec5313154a39a5303610d1cf",
     "grade": true,
     "grade_id": "cell-d53f98d0f4e7704b",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8179\n"
     ]
    }
   ],
   "source": [
    "per_accu = sentimentClassPerceptron('train_data.txt', 'test_data.txt', 100)\n",
    "assert (0.8 < per_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "551d32ae2e800d18fd05af804c55772e",
     "grade": false,
     "grade_id": "cell-b5ca32a7c5be53ed",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def sentimentClassMyOwn(trainFile, testFile):\n",
    "\n",
    "    # Open and read the trainFile and testFile\n",
    "    var= open(trainFile, 'r')\n",
    "    tvar= open(testFile, 'r')\n",
    "\n",
    "    \n",
    "    #random shuffle trainFile before splitting labels\n",
    "    train = []\n",
    "    test = []\n",
    "\n",
    "    train= var.readlines()\n",
    "    test= tvar.readlines()\n",
    "    \n",
    "    var.close()\n",
    "    tvar.close()\n",
    "        \n",
    "    random.shuffle(train)  \n",
    "    random.shuffle(test)\n",
    "    \n",
    "    trainLabels=[]\n",
    "    trainData=[]\n",
    "    testLabels=[]\n",
    "    testData=[]\n",
    "        \n",
    "    # Split label and vector\n",
    "    for elements in train:\n",
    "        trainLabels.append(float(elements.split()[0]))\n",
    "        trainData.append([float(i) for i in elements.split()[1:]])\n",
    "        \n",
    "    for elements in test:\n",
    "        testLabels.append(float(elements.split()[0]))\n",
    "        testData.append([float(i) for i in elements.split()[1:]])\n",
    "     \n",
    "    \n",
    "    #make the first model Logistic Regression\n",
    "   \n",
    "    model1=sklearn.linear_model.LogisticRegression()\n",
    "     # Fit the training set into the model\n",
    "    model1.fit(trainData, trainLabels) #TOOK 4.2 SECONDS TO RUN WITH ACCURACY 86.76%\n",
    "    \n",
    "    \n",
    "     #make the second model SVM but use the support vector classifier class \n",
    "   \n",
    "    model2=sklearn.svm.SVC()\n",
    "     # Fit the training set into the model\n",
    "    model2.fit(trainData, trainLabels) #TOOK 5 MINUTES TO RUN WITH ACCURACY 87.19%\n",
    "\n",
    "    #make the third model Fisher Linear Discriminant Analysis  \n",
    "    model3=sklearn.discriminant_analysis.LinearDiscriminantAnalysis()\n",
    "     # Fit the training set into the model \n",
    "    model3.fit(trainData, trainLabels) #TOOK 2.69 SECONDS TO RUN WITH ACCUURACY 86.74%\n",
    "\n",
    "    # Calculate and return the prediction accuracy\n",
    "    accu1 = model1.score(testData, testLabels)\n",
    "    accu2 = model2.score(testData, testLabels)\n",
    "    accu3 = model3.score(testData, testLabels)\n",
    "    print(accu1)\n",
    "    print(accu2)\n",
    "    print(accu3)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return accu1, accu2, accu3\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0787f69eadc084cd21a0d26285d58280",
     "grade": true,
     "grade_id": "cell-5d9c51d89449cc94",
     "locked": true,
     "points": 30,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8676\n",
      "0.8719\n",
      "0.8674\n"
     ]
    }
   ],
   "source": [
    "accu1, accu2, accu3 = sentimentClassMyOwn('train_data.txt', 'test_data.txt')\n",
    "assert (0.8 < accu1)\n",
    "assert (0.8 < accu2)\n",
    "assert (0.8 < accu3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f83495089b89d49a224ac50fdf5f4e63",
     "grade": true,
     "grade_id": "cell-245e801b01c4fe2a",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Check to make sure you include your report.\n",
    "assert os.path.isfile('Assignment2_Report.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
